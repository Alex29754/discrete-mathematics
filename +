import heapq
from collections import Counter
import math

# Функция для построения кодов Хаффмана для пар символов
def build_huffman_codes(freq):
    heap = [[weight, [pair, ""]] for pair, weight in freq.items()]
    heapq.heapify(heap)
    
    while len(heap) > 1:
        lo = heapq.heappop(heap)
        hi = heapq.heappop(heap)
        for pair in lo[1:]:
            pair[1] = '0' + pair[1]
        for pair in hi[1:]:
            pair[1] = '1' + pair[1]
        heapq.heappush(heap, [lo[0] + hi[0]] + lo[1:] + hi[1:])
    
    huffman_codes = dict(heapq.heappop(heap)[1:])
    return huffman_codes

# Функция для кодирования текста парами символов с использованием кодов Хаффмана
def huffman_encode(text, codes):
    return ''.join([codes[pair] for pair in text])

# Функция для расчёта количества информации по формуле Шеннона
def shannon_entropy(freq, total):
    return -sum((f / total) * math.log2(f / total) for f in freq.values())

# Чтение текста из файла
with open('text.txt', 'r', encoding='utf-8') as file:
    text = file.read()

# Приведение текста к нижнему регистру и удаление лишних символов
text = text.lower()
allowed_chars = set('abcdefghijklmnopqrstuvwxyz ')
text = ''.join([char for char in text if char in allowed_chars])

# Разбиение текста на пары символов
pairs = [text[i:i+2] for i in range(0, len(text)-1, 2)]

# Подсчёт количественной частоты пар символов
pair_frequency = Counter(pairs)
total_pairs = len(pairs)

# Вывод частоты пар символов
print("Частота пар символов:")
for pair, freq in pair_frequency.items():
    print(f"{pair}: {freq}")

# Построение кодов Хаффмана для пар символов
huffman_codes = build_huffman_codes(pair_frequency)

# Кодирование текста парами символов с использованием кодов Хаффмана
encoded_text = huffman_encode(pairs, huffman_codes)
huffman_bits = len(encoded_text)

# Кодирование текста с использованием равномерных 12-битовых кодов (по 6 бит на символ)
uniform_bits = total_pairs * 12

# Расчёт количества информации по формуле Шеннона
entropy = shannon_entropy(pair_frequency, total_pairs)
shannon_bits = entropy * total_pairs

# Вывод результатов
print("\nКоды Хаффмана для пар символов:")
for pair, code in huffman_codes.items():
    print(f"{pair}: {code}")

print(f"\nЗакодированный текст (Хаффман): {encoded_text}")
print(f"Количество бит (Хаффман): {huffman_bits}")
print(f"\nКоличество бит (равномерные 12-битовые коды): {uniform_bits}")
print(f"\nЭнтропия по Шеннону: {entropy:.4f} бит/пара символов")
print(f"Количество информации по Шеннону: {shannon_bits:.4f} бит")

# Сравнение результатов
print("\nСравнение:")
print(f"Хаффман vs равномерные коды: {huffman_bits} бит vs {uniform_bits} бит")
print(f"Хаффман vs Шеннон: {huffman_bits} бит vs {shannon_bits:.4f} бит")
